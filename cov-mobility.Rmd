---
title: "Mobility data"
author: "Robert On"
output:
  html_notebook:
    toc: true
    toc_float: true
---

This notebook explores, validates, and extracts key parameters from public mobility available from Google, Apple, and Descartes Labs. It then goes out to map these key mobility parameters to changes in important outcomes such as Covid fatalities, employment, etc.

# Set up and pulling data

```{r message=FALSE, warning=FALSE}
library(EnvCpt) # for change point detection
library(tidyverse)
library(lubridate)
```

```{r message=FALSE, warning=FALSE}
google_mob <- read_csv(
  "https://www.gstatic.com/covid19/mobility/Global_Mobility_Report.csv",
  # col_types b/c read_csv detects logical in missing values in first 1000 rows.
  col_types = "ccccDnnnnnn", )
# the apple url may need to be manually updated
apple_mob <- read_csv(
  "https://covid19-static.cdn-apple.com/covid19-mobility-data/2007HotfixDev50/v2/en-us/applemobilitytrends-2020-05-06.csv")
descartes_mob <- read_csv(
  "https://raw.githubusercontent.com/descarteslabs/DL-COVID-19/master/DL-us-mobility-daterow.csv")
```

# Data Exploration

## Data summaries

```{r eval=FALSE, include=FALSE}
lapply(list(google_mob, apple_mob, descartes_mob), FUN = function(df) {
  df %>% mutate_if(is.character, as.factor) %>% summary()
})
```

There is some substantial differences in these data sets in their structure, but also on their content. We first tidy up the structure, then we dive into each set of metrics.

## Tidy structure

Google:

```{r}
(google_mob <- google_mob %>%
  gather(location_type, pct_change, contains("percent_change")) %>%
  mutate(location_type = str_remove(location_type,
                                    "_percent_change_from_baseline")))
```

Apple:

```{r}
(apple_mob <- apple_mob %>%
   gather(date, routing_requests, -geo_type, -region, -transportation_type,
          -alternative_name))
```

Descartes:

```{r}
(descartes_mob <- descartes_mob %>%
   gather(metric, value, m50, m50_index))
```


## Google

[Google mobility](https://www.google.com/covid19/mobility/data_documentation.html) measures "the percent change in visits to places like grocery stores and parks within a geographic area". This is split out into six location types (retail/recreation, grocery/pharmacy, parks, transit stations, workplaces, and residential) and measure changes from a baseline date of Feb 15, 2020.

It would be interesting know how visits are counted. Do I need to leave a place to visit that place again? Does staying at home all day mean I visited home just once? These details are not revealed from the [summary](https://www.google.com/covid19/mobility/data_documentation.html).

### Top/Bottom 5 countries by cumulative change

The mobility documentation also warns: "Location accuracy and the understanding of categorized places varies from region to region, so we donâ€™t recommend using this data to compare changes between countries, or between regions with different characteristics (e.g. rural versus urban areas)."

It's a good caveat to think about - but we need to start somewhere:

```{r fig.height=9, fig.width=9}
google_mob %>%
  filter(is.na(sub_region_1) & is.na(sub_region_2)) %>%
  group_by(country_region, location_type) %>%
  mutate(sum_pct_change = sum(abs(pct_change))) %>%
  group_by(location_type) %>% 
  mutate(change_rank_top = dense_rank(sum_pct_change)) %>%
  mutate(change_rank_bot = dense_rank(-sum_pct_change)) %>%
  group_by(country_region) %>%
  filter(any(change_rank_top %in% 1:5 | change_rank_bot %in% 1:5)) %>%
  ggplot(aes(date, pct_change, color = country_region)) +
  facet_wrap(~ location_type, ncol = 2) +
  geom_line() -> p

plotly::ggplotly(p)
```

It appears the countries that have changed the least are Benin, Japan, Taiwan, Tanzania, and Yemen.  Those that changed the most are Bolivia, Ecuador, Italy, Mauritius, and Spain.  In general there is a consistent decline in all categories except parks and residential.  That would more or less align with what we would expect from a stay-at-home order with some outdoor exceptions. Denmark really loves their parks.

### Location aggregates

```{r}
google_mob %>% group_by(country_region) %>%
  summarise(distinct_sr1 = n_distinct(sub_region_1, na.rm = T),
            distinct_sr2 = n_distinct(sub_region_2, na.rm = T)) %>%
  arrange(desc(distinct_sr2), desc(distinct_sr1))
```

The Google mobility data contains two sub-regions for the US (states and counties) and one sub-region for 49 other countries.  The remaining 82 countries do not have any sub-regional information.

## Apple

Apple [defines](https://www.apple.com/covid19/mobility) their measure as "a relative volume of directions requests per country/region or city compared to a baseline volume on January 13th, 2020". So this starts earlier than the Google data and cuts their data by transportation type (driving, walking, or transit).  Perhaps the transit direction requests could be comparable to Google's.

Additionally they define their days as midnight to midnight, Pacific time and point out that there is substantial day of week variation in these requests on a regular basis.

### Top/Bottom 5 countries by cumulative change

We try to replicate the same graph:

```{r fig.height=9, fig.width = 9}
apple_mob %>%
  mutate(date = ymd(date)) %>%
  filter(geo_type == "country/region") %>%
  group_by(region) %>%
  mutate(routing_requests = routing_requests - 100,
         sum_routing_requests = sum(abs(routing_requests))) %>%
  group_by(transportation_type) %>% 
  mutate(change_rank_top = dense_rank(sum_routing_requests)) %>%
  mutate(change_rank_bot = dense_rank(-sum_routing_requests)) %>%
  group_by(region) %>%
  filter(any(change_rank_top %in% 1:5 | change_rank_bot %in% 1:5)) %>%
  ggplot(aes(date, routing_requests, color = region)) +
  geom_line() + facet_wrap(~ transportation_type, scales = "free", ncol = 1) -> p

plotly::ggplotly(p)
```

We see stronger compliance in transit and walking modes with less variation in driving. This appears consistent with a social distancing order keeping people away from being in physical contact with others.

### Location aggregates

```{r}
apple_mob %>%
  group_by(geo_type) %>%
  summarise_at(vars(region), n_distinct)
```

Apple mobility data consists of 63 countries and 89 cities around the world. Much more restricted than what's available in the Google mobility data.

## Descartes

Descartes Labs defines their measure of mobilty as the median of max-distance mobility. The max-distance mobility is the maximum haversine distance (km) from the initial location report of the day.  Furthermore, a normalized measure of this metric is computed by dividing it by a historical (not clearly defined) value in the region. More information can be found in their [technical paper](https://www.descarteslabs.com/wp-content/uploads/2020/03/mobility-v097.pdf). Time series data begins from March 1st.

### Top/Bottom 5 states by cumulative change

```{r fig.height=5, fig.width=8}
descartes_mob %>%
  filter(is.na(admin2) & !is.na(admin1)) %>%
  group_by(admin1) %>%
  filter(metric == "m50_index") %>%
  mutate(sum_m50_index = sum(abs(value))) %>%
  ungroup() %>%
  mutate(change_rank_top = dense_rank(sum_m50_index)) %>%
  mutate(change_rank_bot = dense_rank(-sum_m50_index)) %>%
  group_by(admin1) %>%
  filter(any(change_rank_top %in% 1:5 | change_rank_bot %in% 1:5)) %>%
  ggplot(aes(date, value, color = admin1)) +
  geom_line() -> p

plotly::ggplotly(p)
```

There's quite a bit of red-state/blue-state disparity in these changes from baseline.

### Location aggregates

```{r}
descartes_mob %>%
  select(country_code, admin1, admin2) %>% unique()
```

It looks like we only have US data in the Descartes mobility data - along with state and county breakdowns. Data is rolled up at country, state and county levels.

# Merging sources

Merging and tidying up into: (a) date, (b) geo_type, (c) geo_name, (d) metric_type, (e) value, and (f) source

```{r}
all_mob <- bind_rows(
  apple_mob %>%
    mutate(source = "apple",
           metric = transportation_type) %>%
    mutate(date = ymd(date)) %>%
    mutate(geo_type = recode(geo_type, "country/region" = "country",
                             "city" = "county_city")) %>%
    rename(geo_name = region, value = routing_requests) %>%
    mutate(geo_name = case_when(
      geo_name == "Baltimore" ~ "Baltimore, Maryland",
      geo_name == "Czech Republic" ~ "Czechia",
      geo_name == "Republic of Korea" ~ "South Korea",
      geo_name == "UK" ~ "United Kingdom",
      geo_name == "Washington DC" ~ "District of Columbia, United States",
      TRUE ~ geo_name)) %>%
    mutate(geo_type = if_else(geo_name == "District of Columbia, United States",
                              "state_province", geo_type)) %>%
    mutate(value = value - 100), # %>%
    # group_by(source, geo_type, geo_name, date) %>%
    # summarise(value = mean(value)),
  google_mob %>%
    mutate(source = "google",
           metric = location_type) %>%
    mutate(geo_name = case_when(
      !is.na(sub_region_2) ~ paste(sub_region_2, sub_region_1, sep = ", "),
      !is.na(sub_region_1) ~ paste(sub_region_1, country_region, sep = ", "),
      TRUE ~ country_region)) %>%
    mutate(geo_type = case_when(
      !is.na(sub_region_2) ~ "county_city",
      !is.na(sub_region_1) ~ "state_province",
      TRUE ~ "country")) %>%
    # mutate(pct_change = if_else(location_type == "residential", -pct_change,
    #                             pct_change)) %>%
    rename(value = pct_change) %>%
    mutate(geo_name = str_replace(geo_name, " Parish", " County")),
    # group_by(source, geo_type, geo_name, date) %>%
    # summarise(value = mean(value)),
  descartes_mob %>%
    mutate(source = "descartes") %>%
    mutate(geo_name = case_when(
      admin_level == 0 ~ "United States",
      admin_level == 1 ~ paste0(admin1, ", United States"),
      admin_level == 2 ~ paste(admin2, admin1, sep = ", "),
      TRUE ~ NA_character_)) %>%
    mutate(geo_name = str_replace(geo_name, "^City of ", "")) %>%
    mutate(geo_name = str_replace(geo_name, " City and Borough,", ",")) %>%
    mutate(geo_name = str_replace(geo_name, "^Sainte", "Ste.")) %>%
    mutate(geo_name = str_replace(geo_name, "^Saint", "St.")) %>%
    mutate(geo_name = str_replace(geo_name, " Borough,", ",")) %>%
    mutate(geo_name = str_replace(geo_name, " Municipality,", ",")) %>%
    mutate(geo_name = case_when(
      geo_name == "Washington, D.C., United States" ~
        "District of Columbia, United States",
      geo_name == "Bronx, New York" ~ "Bronx County, New York",
      geo_name == "De Soto County, Mississippi" ~ "DeSoto County, Mississippi",
      TRUE ~ geo_name)) %>%
    mutate(geo_type = case_when(
      admin_level == 0 ~ "country",
      admin_level == 1 ~ "state_province",
      admin_level == 2 ~ "county_city",
      TRUE ~ NA_character_)) %>%
    mutate(value = if_else(metric == "m50_index", value - 100, value)) %>%
    mutate(geo_name = str_replace(geo_name, " Parish", " County"))
    # group_by(source, geo_type, geo_name, date) %>%
    # summarise(value = mean(value))
  ) %>% select(source, geo_type, geo_name, metric, date, value)
```

```{r eval=FALSE, include=FALSE}
all_mob <- bind_rows(
    # Apple Mobility
    apple_mob %>%
      mutate(source = "apple", metric = "routing_requests",
             date = ymd(date)) %>%
      unite(metric, transportation_type, metric) %>%
      rename(value = routing_requests, geo_name = region) %>%
      mutate(geo_name = case_when(
        geo_name == "Baltimore" ~ "Baltimore, Maryland",
        geo_name == "Czech Republic" ~ "Czechia",
        geo_name == "Republic of Korea" ~ "South Korea",
        geo_name == "UK" ~ "United Kingdom",
        geo_name == "Washington DC" ~ "District of Columbia",
        TRUE ~ geo_name
      )) %>%
      mutate(value = value - 100),
    # Google Mobility
    google_mob %>%
      mutate(source = "google") %>%
      # append country_region to sub_region_1
      mutate(sub_region_1 = if_else(!is.na(sub_region_1),
                                    paste(sub_region_1, country_region,
                                          sep = ", "),
                                    sub_region_1)) %>%
      # append sub_region_1 to sub_region_2
      mutate(sub_region_2 = if_else(!is.na(sub_region_2),
                                    paste(sub_region_2, sub_region_1,
                                          sep = ", "),
                                    sub_region_2)) %>%
      mutate(
        country_region = if_else(
          !is.na(sub_region_1) | !is.na(sub_region_2), NA_character_,
          country_region),
        sub_region_1 = if_else(
          !is.na(sub_region_2), NA_character_, sub_region_1)) %>%
      pivot_longer(c(country_region, sub_region_1, sub_region_2),
                   names_to = "geo_type",
                   values_to = "geo_name", values_drop_na = TRUE) %>%
      rename(value = pct_change, metric = location_type) %>%
      select(-country_region_code) %>%
      filter(!is.na(geo_name)),
    # Descartes Mobility
    descartes_mob %>%
      mutate(source = "descartes") %>%
      mutate(m50_index = m50_index - 100) %>%
      mutate(admin2 = if_else(!is.na(admin2), paste(admin2, admin1, sep = ", "),
                              admin2)) %>%
      pivot_longer(c(admin1, admin2),
                   names_to = "geo_type",
                   values_to = "geo_name", values_drop_na = TRUE) %>%
      pivot_longer(c(m50, m50_index),
                   names_to = "metric", values_to = "value") %>%
      mutate(geo_name = str_replace(geo_name, "^City of ", "")) %>%
      mutate(geo_name = str_replace(geo_name, "^Sainte ", "Ste. ")) %>%
      mutate(geo_name = str_replace(geo_name, "^Saint ", "St. ")) %>%
      mutate(geo_name = str_replace(geo_name, " Municipality$", "")) %>%
      mutate(geo_name = str_replace(geo_name, " City and Borough$", "")) %>%
      mutate(geo_name = str_replace(geo_name, " Borough$", "")) %>%
      mutate(geo_name = case_when(
        geo_name == "Bronx" ~ "Bronx County",
        geo_name == "Kenai Peninsula" ~ "Kenai Peninsula Borough",
        geo_name == "Dona Ana County" ~ "DoÃ±a Ana County",
        geo_name == "Washington, D.C." ~ "District of Columbia",
        TRUE ~ geo_name)) %>%
      select(-country_code, -admin_level, -fips, -samples)) %>%
  # normalize geo_type's
  mutate(geo_type = case_when(
    geo_type %in% c("country/region", "country_region") ~ "country",
    geo_type %in% c("sub_region_1", "admin1") ~ "state_province",
    geo_type %in% c("sub_region_2", "admin2", "city") ~ "county_city",
    TRUE ~ "new_geo_type")) %>%

```

# Comparison and validation

## Geo overlap

```{r}
all_mob %>%
  group_by(geo_type, geo_name) %>%
  summarise(n_sources = n_distinct(source),
             sources = str_flatten(unique(source), collapse = ",")) %>%
  arrange(desc(n_sources), geo_type, geo_name) %>% DT::datatable()
```

There are only two locations where all three data sources align in terms of locations.

## Time overlap

```{r}
all_mob %>%
  select(source, date) %>%
  ggplot(aes(y = date, fill = source)) +
  geom_boxplot(alpha = 0.2) + coord_flip()
```

Apple covers the largest range of time and starts the earliest. Descartes starts the latest but also seems to have the most updated data.  Google is in the middle of the pack.

## Google/Apple/Descartes

These sources overlap in only two places, Baltimore and Washington DC.

```{r}
all_mob %>%
  group_by(geo_type, geo_name) %>%
  mutate(n_sources = n_distinct(source),
         sources = str_flatten(unique(source), collapse = ","),
         week = floor_date(date, "week")) %>%
  filter(n_sources == 3) %>%
  group_by(week, geo_name, metric) %>%
  summarise(value = mean(value)) %>%
  ggplot(aes(week, value, color = metric)) +
  theme(legend.position = "bottom") +
  facet_wrap(~ geo_name, ncol = 1) +
  geom_line() -> p
plotly::ggplotly(p)
```

## Google/Apple

Apple/Google overlap happens at the country level.  Furthermore, we should expect that Google's transit station visits aligns well with Apple's transit direction requests.

```{r fig.height=12, fig.width=8}
all_mob %>%
  group_by(geo_type, geo_name) %>%
  mutate(n_sources = n_distinct(source),
         sources = str_flatten(unique(source), collapse = ","),
         week = floor_date(date, "week")) %>%
  filter(n_sources == 2 & sources == "apple,google") %>%
  unite(metric, source, metric) %>%
  group_by(week, geo_name, metric) %>%
  summarise(value = mean(value)) %>%
  ggplot(aes(week, value, color = geo_name)) +
  facet_wrap(~ metric, ncol = 2) +
  geom_line() -> p
plotly::ggplotly(p)
```

### Transit correlations

```{r fig.height=12, fig.width=6}
all_mob %>%
  filter(metric %in% c("transit",
                       "transit_stations")) %>%
  group_by(geo_name, date) %>%
  filter(any(source == "apple") & any(source == "google")) %>%
  arrange(geo_type, geo_name, date) %>%
  ggplot(aes(date, value, color = source)) +
  geom_line() + facet_wrap(~ geo_name, ncol = 3) +
  theme(legend.position = "bottom")
```

```{r}
all_mob %>%
  filter(metric %in% c("transit",
                       "transit_stations")) %>%
  group_by(geo_name, date) %>%
  filter(any(source == "apple") & any(source == "google")) %>%
  ungroup() %>%
  select(-geo_type, -metric) %>%
  spread(source, value) %>%
  group_by(geo_name) %>%
  mutate_at(vars(apple, google), scale) %>%
  summarise(correlation = cor(apple, google)) %>%
  mutate(geo_name = if_else(geo_name %in% c("Taiwan", "Japan"),
                            "Taiwan/Japan", "All other countries")) %>%
  arrange(correlation) %>%
  ggplot(aes(correlation, fill = geo_name)) + geom_density(alpha = 0.2)
```

Looks like correlations do better in Western countries vs Eastern countries but generally high correlations everywhere except for Taiwan and Japan.

## Google/Descartes

There are a lot of counties so we randomly sample 10 for display.

```{r fig.height=12, fig.width=8}
all_mob %>%
  group_by(geo_type, geo_name) %>%
  filter(n_distinct(source) == 2 &
           all(source == "google" | source == "descartes")) %>%
  unite(metric, source, metric) %>%
  group_by(week = floor_date(date, "week"), geo_name, metric) %>%
  summarise(value = mean(value)) %>%
  group_by(geo_name) %>% nest() %>% ungroup() %>%
  sample_n(10) %>% unnest(cols = c(data)) %>%
  ggplot(aes(week, value, color = metric)) +
  facet_wrap(~ geo_name, ncol = 2) +
  geom_line() -> p
plotly::ggplotly(p)
```

We note that m50 is actually a positive value in kilometers so doesn't have the same "percent change from baseline" that is used in other metrics.

### Residential correlations

Similar to the transit information between Google/Apple - we look for some correlations between Descartes/Google residential vs non-residential movement.

```{r}
all_mob %>%
  filter(source %in% c("google", "descartes")) %>%
  filter(geo_type == "county_city" & metric != "m50") %>%
  mutate(metric = if_else(metric %in% c("residential", "m50_index", "m50"),
                          metric, "m50_index_goog")) %>%
  group_by(geo_type, geo_name, metric, date, source) %>%
  summarise(value = mean(value, na.rm = TRUE)) %>%
  #mutate(value = if_else(metric == "residential", value * -1, value)) %>%
  group_by(metric, date) %>%
  summarise_at(vars(value), mean, na.rm=TRUE) %>%
  ggplot(aes(date, value, color = metric)) + geom_line()
```

```{r}
all_mob %>%
  filter(source %in% c("google", "descartes")) %>%
  filter(geo_type == "county_city" & metric != "m50") %>%
  mutate(metric = if_else(metric %in% c("residential", "m50_index", "m50"),
                          metric, "m50_index_goog")) %>%
  group_by(geo_type, geo_name, metric, date, source) %>%
  summarise(value = mean(value, na.rm = TRUE)) %>% ungroup() %>%
  select(geo_name, metric, date, value) %>%
  spread(metric, value) %>%
  group_by(geo_name) %>%
  filter(any(!is.na(m50_index) & any(!is.na(m50_index_goog)))) %>%
  group_by(geo_name) %>%
  summarise(correlation_m50 = cor(m50_index, m50_index_goog,
                                  use = "pairwise.complete.obs"),
            correlation_res = cor(m50_index, residential,
                                  use = "pairwise.complete.obs")) %>%
  gather(correlation_type, correlation, starts_with("correlation_")) %>%
  arrange(-correlation) %>%
  ggplot(aes(correlation, fill = correlation_type)) +
  geom_density(alpha = 0.1)
```

This is all reassuring, Google residential activity is negatively correlated with the `m50_index` from Descartes. The average of all non-residential activities from Google is positively correlated to the `m50_index`. The residential negative correlation does appear stronger over these different regions than non-residential Google mobility data.

# Aggregating and cleaning data

Below we aggregate data into measures that reflect declining mobility. This means aggregating all the Apple metrics directly, aggregating all the Google metrics treating residential activity inversely, and using the normalized Descartes measure directly. We also interpolate data missing in the Google data due to privacy thresholds.

## Missingness

```{r}
all_mob %>%
  group_by(geo_type, metric, source) %>%
  summarise(na_pct = mean(is.na(value))) %>%
  arrange(desc(na_pct))
```

Google is missing a fair bit of data in its stats about parks, transit_stations, and residential - especially at the county level. It's a little strange that there is missing data at the state level and the order of missingness is reversed from the county level. There is this general issue where data is censored when there are very few people in a location or location category - so maybe the missingness is information in itself - like a lower bound on the amount of activity in a given place. This missingness is likely to cause some problems so we should come up with a way to deal with it.

We create `all_mob_fix` which adds another column, `value_type` that helps us distinguish between values interpolated by `na.approx` and original values.  There are many spotty values, especially at the county level, in the Google data so this is necessary to do anything useful.

## Filling and aggregating

```{r}
(all_mob_fix <- all_mob %>%
   # fill in missing values
   group_by(metric, geo_type, geo_name, source) %>%
   mutate(value_approx = na.approx(value, na.rm = FALSE)) %>%
   gather(value_type, value, value, value_approx) %>%
   ungroup() %>% 
   # aggregate google mobility metrics
   mutate(value = if_else(metric == "residential", value * -1, value)) %>%
   mutate(metric = if_else(source == "google", "google_mob", metric)) %>%
   mutate(metric = if_else(source == "apple", "apple_mob", metric)) %>%
   filter(metric != "m50") %>%
   mutate(metric = if_else(source == "descartes", "descartes_mob", metric)) %>%
   group_by(metric, geo_type, geo_name, source, value_type, date) %>%
   summarise(value = mean(value, na.rm = TRUE)) %>%
   ungroup()) #%>%
  # group_by(metric, geo_type, geo_name, source) %>% pull(pct_value) %>% hist()
  # filter(any(between(pct_value, 0.96, 0.97))) %>% 
  # filter(rbinom(1, 1, 0.1) == 1) %>%
  # ggplot(aes(date, value)) +
  # facet_grid(geo_name ~ value_type) +
  # geom_line()
```

# Mobility parameters

We'd like to be able to extract key parameters from the aggregated mobility time series.  Specifically we're interested in (1) when the declines in mobility began, (2) how quickly and by how much did mobility decline, and (3) is there any evidence of a reopening.

## Change point detection

This algorithm looks for significant changes in time series over time and helps us find the points in time when these changes occurred.

```{r message=FALSE, warning=FALSE}
help_envcpt <- function(df) {
  if (sum(!is.na(df$value)) < 14) {
    return(NA) 
  } else {
    return(list(envcpt(na.approx(df$value), verbose = FALSE)))
  }
}

mob_cpt_file <- "data/all_mob_cpt.rds"
refresh <- FALSE

if (!file.exists(mob_cpt_file) || refresh) {
 all_mob_cpt <- all_mob_fix %>%
   filter(value_type == "value_approx") %>%
   group_by(geo_type, geo_name, source, metric) %>%
   nest() %>% rowwise() %>%
   mutate(cpt_mdl = help_envcpt(data)) 
 saveRDS(all_mob_cpt, mob_cpt_file)
} else {
  all_mob_cpt <- readRDS(mob_cpt_file)
}
```

```{r}
all_mob_cpt %>% rowwise() %>%
  mutate(has_mdl = all(!is.na(cpt_mdl))) %>%
  group_by(geo_type, metric) %>%
  summarise(has_mdl = mean(has_mdl)) %>%
  arrange(has_mdl)
```

Most models were able to run with the exception of a few, probably due to sparse data.

## Extract mobility parameters

```{r}
extract_mob_parameters <- function(cpt_data, cpt_mdl, mdl_name = "meancpt") {
  if (any(is.na(cpt_mdl))) {
    return(NA)
  }
  cpt_mdl <- cpt_mdl[[mdl_name]]
  dates <- cpt_data %>% pull(date)
  values <- cpt_data %>% pull(value)
  
  means <- cpt_mdl@param.est$mean
  vars <- cpt_mdl@param.est$variance
  
  end_pts <- cpt_mdl@cpts
  seg_lens <- seg.len(cpt_mdl)
  start_pts <- (end_pts - seg_lens) + 1
  
  eq_idx <- head(order(seg_lens, decreasing = T), 2)
  min_idx <- which.min(means)
  max_idx <- which.max(means)
  first_idx <- min(min_idx, max_idx)
  last_idx <- max(min_idx, max_idx)
  
  # important vals
  change_start <- end_pts[first_idx]
  change_end <- start_pts[last_idx]
  
  # save vals
  change_start_date <- dates[change_start]
  change_end_date <- dates[change_end]
  
  mean_before <- means[first_idx]
  mean_after <- means[last_idx]
  var_before <- vars[first_idx]
  var_after <- vars[last_idx]
  change_diff <- mean_after - mean_before
  change_slope <- change_diff / (last_idx - first_idx)
  start_seg <- c(start_pts[first_idx], end_pts[first_idx])
  start_seg_dates <- dates[start_seg]
  end_seg <- c(start_pts[last_idx], end_pts[last_idx])
  end_seg_dates <- dates[end_seg]
  revert <- last(means) - mean_after
  
  data.frame(
    change_start_date = change_start_date,
    change_diff = change_diff,
    change_slope = change_slope,
    change_end_date = change_end_date,
    change_days = change_end_date - change_start_date,
    mean_before = mean_before,
    mean_after= mean_after,
    var_before = var_before,
    var_after= var_after,
    seg_start_date = dates[start_pts[first_idx]],
    seg_end_date = dates[end_pts[last_idx]],
    revert = revert)
}

all_mob_params <- all_mob_cpt %>%
  rowwise() %>%
  mutate(
    cpt_params = list(extract_mob_parameters(data, cpt_mdl))) %>%
  unnest(cpt_params) %>% ungroup()
```

```{r}
plot_row <- function(x) {
  x %>% pluck("cpt_mdl", 1) %>% .[["meancpt"]] %>% plot()
}

all_mob_params %>%
  arrange(change_slope) %>%
  select(source, geo_name, change_slope) %>%
  head(1000) %>%
  DT::datatable()
```

The first thing that pops out are Descartes numbers are wild (and likely very noisy).  We should probably ignore them.

```{r}
all_mob_params %>%
  filter(source != "descartes") %>%
  arrange(change_slope) %>%
  select(source, geo_name, change_slope) %>%
  head(1000) %>%
  DT::datatable()
```

Apple and Google change from baseline metrics look reasonable.  We'll use Google for a region level analysis and Apple+Google for country level changes.

```{r}
all_mob_params %>%
  filter(geo_type == "country") %>%
  select(source, geo_name, change_start_date) %>%
  spread(source, change_start_date) %>%
  ggplot(aes(google, apple, labels = geo_name)) + geom_point() +
  ylim(as.Date("2020-01-15"), today()) + xlim(as.Date("2020-01-15"), today()) +
  geom_abline(slope = 1) -> p
plotly::ggplotly(p)
```

Most of the change dates in march are in agreement - but some earlier change dates picked up by Apple aren't picked up by Google because the data set started later than Apple. Also it appears the Google data is adjusted for some level of weekly seasonality?

```{r}
all_mob_params %>%
  filter(geo_name == "France") %>%
  select(source, data) %>%
  unnest(data) %>%
  ggplot(aes(date, value, color = source)) +
  geom_line()
```


```{r}
all_mob_params %>%
  filter(geo_type == "country" & source != "descartes") %>%
  select(source, geo_name, change_start_date) %>%
  spread(source, change_start_date) %>%
  mutate(diff = abs(google - apple)) %>%
  arrange(desc(diff))
```

Here we see that many Asia region countries and countries that started their shutdown earlier were picked up in the Apple data earlier. For countries that started their shutdown later in March there wasn't as much of a difference - which is promising for our change point detecton model.

```{r}
all_mob_params %>%
  filter(geo_name == "France") %>% slice(1) %>% plot_row()

all_mob_params %>%
  filter(geo_name == "France") %>% slice(2) %>% plot_row()
```


```{r}
all_mob_params %>%
  filter(geo_name == "Hong Kong") %>% slice(1) %>% plot_row()

all_mob_params %>%
  filter(geo_name == "Hong Kong") %>% slice(2) %>% plot_row()
```

Google looks like they are not getting the correct shutdown dates for early implementesr because the time series only begins in March while Apple's start in April.  At least for the late implementers, the numbers seem to align reasonably well.  This tells us that using Google data for an international comparison may not be useful because countries didn't start until earlier. For countries like Italy, who started later (sadly), we are able to see the change points and it looks like we're able to pick up the start date correctly.

```{r}
all_mob_params %>%
  filter(geo_name == "Italy") %>% slice(1) %>% plot_row()

all_mob_params %>%
  filter(geo_name == "Italy") %>% slice(2) %>% plot_row()
```

```{r}
all_mob_params %>%
  filter(geo_name == "Taiwan") %>% slice(1) %>% plot_row()

all_mob_params %>%
  filter(geo_name == "Taiwan") %>% slice(2) %>% plot_row()
```

Since Taiwan started their reduction in mobility so early, Google's mobility data couldn't pick up any changes at all leading to a large disparity in dates.

```{r}
all_mob_params %>%
  filter(geo_name == "Japan") %>% slice(1) %>% plot_row()

all_mob_params %>%
  filter(geo_name == "Japan") %>% slice(2) %>% plot_row()
```

Japan started later and we were able to pick up the same change at the same later date.

```{r}
all_mob_params %>%
  #ggplot(aes(source, change_slope)) +
  ggplot(aes(source, change_slope)) +
  geom_boxplot() + coord_flip()
```

Descartes has a lot of outliers that seem not very plausible, lets bound these values within 100.

```{r}
all_mob_params %>%
  filter(abs(change_slope) < 100) %>%
  #ggplot(aes(source, change_slope)) +
  ggplot(aes(source, change_slope)) +
  facet_wrap(~ geo_type, ncol = 1) +
  geom_boxplot() + coord_flip()
```

# SIPO Compliance

## Most change

```{r}
all_mob_params %>%
  filter(source != "descartes") %>%
  arrange(desc(abs(change_slope))) %>%
  select(metric, geo_type, geo_name, change_start_date, change_slope, revert,
         change_diff, change_end_date, change_days, mean_before,
         mean_after, var_before, var_after) %>%
  DT::datatable()
```

## Least change

```{r}
all_mob_params %>%
  filter(source != "descartes") %>%
  arrange(abs(change_slope)) %>%
  select(metric, geo_type, geo_name, change_start_date, change_slope, revert,
         change_diff, change_end_date, change_days, mean_before,
         mean_after, var_before, var_after) %>%
  DT::datatable()
```

## Most reverting

```{r}
all_mob_params %>%
  filter(source != "descartes") %>%
  arrange(desc(abs(revert))) %>%
  select(metric, geo_type, geo_name, change_start_date, change_slope, revert,
         change_diff, change_end_date, change_days, mean_before,
         mean_after, var_before, var_after) %>%
  DT::datatable()
```

We can explore this data table to examine when and by how much each location began their mobility reductions and if there are signs of reversion to this mobility trend.

```{r}
all_mob_params %>%
  filter(geo_name == "Kootenai County, Idaho" & source == "google") %>% 
  plot_row()

all_mob_params %>%
  filter(geo_name == "Costa Rica" & source == "google") %>% plot_row()

all_mob_params %>%
  filter(geo_name == "Norway" & source == "apple") %>% plot_row()

all_mob_params %>%
  filter(geo_name == "Polk County, Wisconsin" & source == "google") %>%
  plot_row()
```
```{r}
all_mob_params %>%
  filter(geo_name == "Orange County, California" & source == "google") %>%
  plot_row()
```

```{r}
all_mob_params %>%
  filter(geo_name == "Singapore" & source == "google") %>% plot_row()
all_mob_params %>%
  filter(geo_name == "Singapore" & source == "apple") %>% plot_row()
```

## Official policy dates

[Keystone](https://github.com/Keystone-Strategy/covid19-intervention-data/) provides hand-curated information on when certain policies were declared. Since any of these policies could have changed mobility behavior we look at the change point detected date vs the policy date and see which counties started earlier or later than the policy prescribed date.

```{r}
ks_npi <- read_csv("https://raw.githubusercontent.com/Keystone-Strategy/covid19-intervention-data/master/complete_npis_inherited_policies.csv")

(goog_mob_params <- all_mob_params %>%
   filter(source == "google") %>%
   left_join(
     ks_npi %>%
       mutate(geo_name = if_else(is.na(county), state,
                                 paste(county, "County,", state)),
              geo_type = if_else(is.na(county), "state_province", "county_city"),
              start_date = mdy(start_date),
              end_date = mdy(end_date)) %>%
       group_by(geo_name) %>%
       summarise(keystone_first_date = min(start_date, na.rm = TRUE)),
     by = "geo_name")) %>%
  filter_at(vars(ends_with("_date")), ~ !is.na(.)) %>%
  mutate(label = paste(source, geo_name)) %>%
  ggplot(aes(change_start_date, keystone_first_date, labels = label)) +
  geom_point() + geom_abline(slope = 1) -> p
plotly::ggplotly(p)
```

To the left of the line are locations that started changing before the date, and to the right of the line are locations that changed afterwards. This gives us an idea of policy compliance as well as other motivating factors (apart from policy) that drive behavior.

## SIPO implementation timing

```{r fig.height=12, fig.width=9}
all_mob_params %>%
  filter(geo_type == "county_city" & source == "google") %>%
  select(geo_name, change_start_date, change_end_date, change_diff) %>%
  mutate(rank = dense_rank(change_diff)) %>%
  mutate(geo_name = fct_rev(fct_reorder(geo_name, change_start_date))) %>%
  gather(date_type, date, change_start_date, change_end_date) %>%
  filter(rank %in% c(1:100)) %>%
  ggplot(aes(geo_name, date, color = change_diff)) + geom_line(size = 1) + 
  coord_flip()
```

Here we observe variation in when the decline in mobility started, how long it took to bottom out and how severe it was (color). A large fast change suggest a jurisdiction that was able to comply well.

```{r}
all_mob_params %>%
  filter(geo_name == "Calaveras County, California" & source == "google") %>% plot_row()
all_mob_params %>%
  filter(geo_name == "Cook County, Minnesota" & source == "google") %>% plot_row()
```


# Covid deaths

Next steps involve looking at variation in these mobility measures and how they map to variation in Covid-19 fatalities. First we pull down covid data from JHU, New York Times, Corona Data Scraper, and the Covid Tracking Project.

## Data prep

```{r}
setwd("../covid-compare/")
source("covidcomp_lib.R")
jhu <- fetchPrepJhuData()
covtrack <- fetchPrepCovTrackData(add_flu = FALSE)
nyt <- fetchPrepNyt()
cds <- fetchPrepCorDataScrape()
```

### Data join with mobility

```{r}
deaths <- bind_rows(
  jhu %>%
    rename(geo_name = country) %>%
    mutate(geo_type = "country", source = "jhu"),
  covtrack %>%
    rename(geo_name = state) %>%
    mutate(geo_type = "state_province", source = "ctp") %>%
    mutate(geo_name = str_replace(geo_name, "USA", "United States")),
  nyt %>%
    rename(geo_name = county) %>%
    mutate(geo_type = "county_city", source = "nyt"),
  cds %>%
    rename(geo_name = location) %>%
    mutate(geo_name = if_else(str_detect(geo_name, "County"),
                              str_remove(geo_name, ", United States"), 
                              geo_name),
           geo_type = if_else(str_detect(geo_name, "County"), "county_city",
                              "state_county"),
           source = "cds")) %>%
  filter(stat %in% c("deaths", "confirmed")) %>%
  # geo_name
  mutate(geo_name = case_when(
    geo_name == "Korea, South" ~ "South Korea",
    geo_name == "US" ~ "United States",
    geo_name == "Taiwan*" ~ "Taiwan",
    geo_name == "Burma" ~ "Myanmar (Burma)",
    str_detect(geo_name, "Puerto Rico") ~ "Puerto Rico",
    geo_name == "New York City, New York" ~ "New York City",
    geo_name == "Cabo Verde" ~ "Cape Verde",
    geo_name == "Cote d'Ivoire" ~ "CÃ´te d'Ivoire",
    geo_name == "Bahamas" ~ "The Bahamas",
    geo_name == "DeSoto County, Mississippi" ~ "DeSoto County, Mississippi",
    geo_name == "Bedford County, Virginia" ~ "Bedford, Virginia",
    geo_name == "Oglala Lakota County, South Dakota" ~
      "Shannon County, South Dakota",
    TRUE ~ geo_name)) %>%
  mutate(geo_name = str_replace(geo_name, " Borough,", ",")) %>%
  mutate(geo_name = str_replace(geo_name, " Municipality,", ",")) %>%
  mutate(geo_name = str_replace(geo_name, " city County", "")) %>%
  # geo_type
  mutate(geo_type = case_when(
    geo_name == "Hong Kong" ~ "country",
    geo_name == "RÃ©union" ~ "country",
    geo_name == "Puerto Rico" ~ "country",
    TRUE ~ geo_type))
```

### Mobility to deaths matching data sources

```{r}
(mob_deaths <- all_mob_params %>%
  left_join(
    deaths %>% group_by(source, geo_type, geo_name, stat) %>%
      nest(deaths = c(date, popM, total)) %>% ungroup() %>%
      mutate(source = fct_relevel(source, "jhu", "ctp", "nyt", "cds")),
    by = c("geo_name", "geo_type")) %>%
  group_by(geo_type, geo_name) %>%
  arrange(source.y) %>%
  filter(source.y == first(source.y))) %>%
  group_by(source.x, source.y, geo_type) %>% count() %>% arrange(desc(n))
```

## Estimating Impact

Ultimately we want to estimate the impact of these mobility reductions on Covid deaths averted, as well as other outcomes such as employment or business activity.

### CausalImpact

We try to use the `CausalImpact` package to estimate this effect with the ~3000 timeseries of Covid deaths at the US county level.

```{r}
fix_ts <- function(col) {
  col[1] <- ifelse(is.numeric(col), 0, FALSE)
  for (i in 1:length(col)) {
    if (is.na(col[i])) {
      col[i] <- col[i - 1]
    }
  }
  return(col)
}

ci <- mob_deaths %>%
  ungroup() %>%
  filter(source.x == "google" & geo_type == "county_city") %>%
  unnest(deaths) %>%
  select(geo_name, change_end_date, date, popM, total) %>%
  group_by(geo_name) %>%
  mutate(sipo = date >= change_end_date) %>%
  select(-change_end_date, -total) %>%
  pivot_wider(names_from = c(geo_name), values_from = c(popM, sipo)) %>%
  arrange(date) %>%
  mutate_at(vars(starts_with("popM_"), starts_with("sipo_")), ~ fix_ts(.)) %>%
  select(date,
         `popM_Orleans County, Louisiana`,
         `sipo_Orleans County, Louisiana`,
         starts_with("popM_"))
```

```{r}
mob_deaths %>% ungroup() %>%
  filter(source.x == "google" & geo_type == "county_city") %>%
  select(geo_name, change_start_date, change_slope, deaths) %>%
  group_by_at(vars(-deaths)) %>%
  unnest(deaths) %>%
  filter(any(popM > 0)) %>%
  summarise(first_death_date = min(date[popM > 0], na.rm = TRUE),
            max_deaths = max(popM)) %>%
  mutate(deaths_per_day = max_deaths / as.numeric(today() - first_death_date),
         time_to_react = change_start_date - first_death_date) %>%
  ungroup() %>% drop_na() %>%
  lm(max_deaths ~ time_to_react, data = .)  %>% summary()
```
```{r}
mob_deaths %>% ungroup() %>%
  filter(source.x == "google" & geo_type == "county_city") %>%
  select(geo_name, change_start_date, change_slope, deaths) %>%
  group_by_at(vars(-deaths)) %>%
  unnest(deaths) %>%
  arrange(date) %>%
  mutate(
    half_date = date[sapply(1:length(popM), FUN = function(i) {
      suppressWarnings(
        max(which((popM)[1:i] <=
                      (popM)[i]/2), na.rm = TRUE))})],
      double_days = date - half_date) %>%
  filter(any(popM > 0)) %>%
  mutate(first_death_date = min(date[total > 0], na.rm = TRUE),
         max_popM = max(popM), max_total = max(total)) %>%
  filter(max_total >= 10) %>%
  mutate(tenth_death_date = min(date[total >= 10]),
         fifth_death_date = min(date[total >= 5]),
         days_since_5 = date - fifth_death_date,
         days_since_10 = date - tenth_death_date,
         avg_double_days = mean(double_days[days_since_5 >= 0 &
                                              days_since_5 <= 14])) %>%
  filter(max(days_since_5) >= 14) %>%
  nest(deaths = c(date, popM, total)) %>%
  mutate(deaths_per_day = max_popM / as.numeric(today() - first_death_date),
         time_to_react = as.numeric(change_start_date - first_death_date)) %>%
  ungroup() %>% drop_na() %>%
  arrange(desc(max_total)) %>%
  ggplot(aes(time_to_react, avg_double_days, label = geo_name)) +
  geom_point() +
  geom_smooth(method = "lm") +
  theme(legend.position = "none") -> p
plotly::ggplotly(p)
```

```{r}
library(CausalImpact)

sipo_status <- ci$`sipo_Orleans County, Louisiana`
dates <- ci$date

pre_period <- range(dates[!sipo_status])
post_period <- range(dates[sipo_status])

data <- ci %>% select(-starts_with("sipo_"), -date) %>%
  tibble(.name_repair = "universal")

data <- data[,apply(data, 2, FUN = function(x) { var(!sipo_status * x) != 0 })]
data <- zoo(data, dates)
data <- data[,apply(data, 2, function(x) { var(x[!sipo_status]) != 0 })]

impact <- CausalImpact(data, pre_period, post_period)
plot(impact)
summary(impact, "report")
```
